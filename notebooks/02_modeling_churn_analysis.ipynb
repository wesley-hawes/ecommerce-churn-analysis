{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eac42dd-2724-4323-85ba-a460490e1ffa",
   "metadata": {},
   "source": [
    "# Churn Prediction Modeling\n",
    "\n",
    "This notebook builds predictive models to estimate customer churn risk\n",
    "using insights derived from exploratory data analysis. The goal is to\n",
    "establish an interpretable baseline model and evaluate its performance\n",
    "using applicable classification metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bacee53b-9d9d-4e5a-b135-d96165298f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8ddad51-7684-4124-bf6e-df07b87585dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Churn</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>PreferredLoginDevice</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>WarehouseToHome</th>\n",
       "      <th>PreferredPaymentMode</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HourSpendOnApp</th>\n",
       "      <th>NumberOfDeviceRegistered</th>\n",
       "      <th>PreferedOrderCat</th>\n",
       "      <th>SatisfactionScore</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfAddress</th>\n",
       "      <th>Complain</th>\n",
       "      <th>OrderAmountHikeFromlastYear</th>\n",
       "      <th>CouponUsed</th>\n",
       "      <th>OrderCount</th>\n",
       "      <th>DaySinceLastOrder</th>\n",
       "      <th>CashbackAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50001</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Mobile Phone</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Debit Card</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Laptop &amp; Accessory</td>\n",
       "      <td>2</td>\n",
       "      <td>Single</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>159.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50002</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phone</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>UPI</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>3</td>\n",
       "      <td>Single</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50003</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phone</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Debit Card</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>3</td>\n",
       "      <td>Single</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50004</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Phone</td>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Debit Card</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Laptop &amp; Accessory</td>\n",
       "      <td>5</td>\n",
       "      <td>Single</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>134.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Phone</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>CC</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>5</td>\n",
       "      <td>Single</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>129.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Churn  Tenure PreferredLoginDevice  CityTier  WarehouseToHome  \\\n",
       "0       50001      1     4.0         Mobile Phone         3              6.0   \n",
       "1       50002      1     NaN                Phone         1              8.0   \n",
       "2       50003      1     NaN                Phone         1             30.0   \n",
       "3       50004      1     0.0                Phone         3             15.0   \n",
       "4       50005      1     0.0                Phone         1             12.0   \n",
       "\n",
       "  PreferredPaymentMode  Gender  HourSpendOnApp  NumberOfDeviceRegistered  \\\n",
       "0           Debit Card  Female             3.0                         3   \n",
       "1                  UPI    Male             3.0                         4   \n",
       "2           Debit Card    Male             2.0                         4   \n",
       "3           Debit Card    Male             2.0                         4   \n",
       "4                   CC    Male             NaN                         3   \n",
       "\n",
       "     PreferedOrderCat  SatisfactionScore MaritalStatus  NumberOfAddress  \\\n",
       "0  Laptop & Accessory                  2        Single                9   \n",
       "1              Mobile                  3        Single                7   \n",
       "2              Mobile                  3        Single                6   \n",
       "3  Laptop & Accessory                  5        Single                8   \n",
       "4              Mobile                  5        Single                3   \n",
       "\n",
       "   Complain  OrderAmountHikeFromlastYear  CouponUsed  OrderCount  \\\n",
       "0         1                         11.0         1.0         1.0   \n",
       "1         1                         15.0         0.0         1.0   \n",
       "2         1                         14.0         0.0         1.0   \n",
       "3         0                         23.0         0.0         1.0   \n",
       "4         0                         11.0         1.0         1.0   \n",
       "\n",
       "   DaySinceLastOrder  CashbackAmount  \n",
       "0                5.0          159.93  \n",
       "1                0.0          120.90  \n",
       "2                3.0          120.28  \n",
       "3                3.0          134.07  \n",
       "4                3.0          129.60  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load raw data \n",
    "cust_df = pd.read_excel(\"../data/ecommerce_churn.xlsx\", sheet_name=\"E Comm\")\n",
    "\n",
    "cust_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d524e3b2-d06e-4a04-98e4-f5ceb82806c6",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Apply preprocessing steps identified during EDA, including missing value\n",
    "treatment, feature engineering, and encoding, to prepare the dataset\n",
    "for future modeling. This helps increase reproducibility in the preprocessing step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb7468e1-ecc2-453a-9cc2-fa67127cc7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['PreferredLoginDevice',\n",
       "  'PreferredPaymentMode',\n",
       "  'Gender',\n",
       "  'PreferedOrderCat',\n",
       "  'MaritalStatus'],\n",
       " ['Tenure',\n",
       "  'CityTier',\n",
       "  'WarehouseToHome',\n",
       "  'HourSpendOnApp',\n",
       "  'NumberOfDeviceRegistered',\n",
       "  'SatisfactionScore',\n",
       "  'NumberOfAddress',\n",
       "  'Complain',\n",
       "  'OrderAmountHikeFromlastYear',\n",
       "  'CouponUsed',\n",
       "  'OrderCount',\n",
       "  'DaySinceLastOrder',\n",
       "  'CashbackAmount'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#separate features from target variable\n",
    "cust_df = cust_df.drop(columns = ['CustomerID'])\n",
    "X = cust_df.drop(columns = ['Churn'])\n",
    "y = cust_df['Churn'].astype('int')\n",
    "\n",
    "#define dtypes for pipeline separation\n",
    "cols_category = X.select_dtypes(include = ['object']).columns.tolist()\n",
    "cols_numeric = X.select_dtypes(exclude = ['object']).columns.tolist()\n",
    "\n",
    "cols_category, cols_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4e108f-f284-426c-92ec-fc45e86f6631",
   "metadata": {},
   "source": [
    "## Modeling Pipeline\n",
    "\n",
    "A scikit-learn Pipeline with a ColumnTransformer is used to combine preprocessing\n",
    "and modeling into a single, reproducible workflow. This ensures that imputation,\n",
    "encoding, and scaling are learned only from the training data, preventing data\n",
    "leakage and allowing consistent application to new data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f3768b1-ebd5-4844-a3e7-f60e9915dcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreferredLoginDevice has 3 unique values\n",
      "PreferredPaymentMode has 7 unique values\n",
      "Gender has 2 unique values\n",
      "PreferedOrderCat has 6 unique values\n",
      "MaritalStatus has 3 unique values\n"
     ]
    }
   ],
   "source": [
    "#see if theres wnough unique levels to justify another encoding technique\n",
    "for col in cols_category:\n",
    "    print(f\"{col} has {cust_df[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe812f15-83db-4168-9c9d-0ffe2a1df6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test splits, use stratify to keep class balance uniform\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7efd359-5252-4de6-b6f3-1649b4ec6759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate CouponUsed to preserve business logic from EDA\n",
    "#missing coupon usage implies no coupon was used\n",
    "coupon_col = [\"CouponUsed\"]\n",
    "other_numeric_cols = [col for col in cols_numeric if col != \"CouponUsed\"]\n",
    "\n",
    "#Categorical preprocessing:\n",
    "#impute missing categories and one hot encode\n",
    "cat_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "#Numeric preprocessing:\n",
    "#median imputation with missingness indicators, then scaling\n",
    "numeric_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "#Coupon preprocessing:\n",
    "#zero-imputation reflects absence of coupon usage, with missingness indicator\n",
    "coupon_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=0, add_indicator=True)),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "#Combine preprocessing steps by feature type\n",
    "full_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pipe, other_numeric_cols),\n",
    "        (\"coupon\", coupon_pipe, coupon_col),\n",
    "        (\"cat\", cat_pipe, cols_category),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "#Full classification pipeline to prevent data leakage\n",
    "classification_pipe = Pipeline(steps=[\n",
    "    (\"preprocess\", full_transformer),\n",
    "    (\"model\", LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df2eb16-7100-4d00-8b79-0401765eeb4c",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "5-fold stratified cross-validation is run on the training set to help simulate how my model would preform on unseen data/sampling variation. Preprocessing is included inside the pipeline to prevent data leakage within each fold. Final results are reported\n",
    "on a held-out test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa47e12d-7d39-4037-83f9-b82df7177a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc_auc': (0.8941929889013199, 0.0157601135502362),\n",
       " 'precision': (0.46398772429134016, 0.02550091573331306),\n",
       " 'recall': (0.8199743918053779, 0.015772444430971404),\n",
       " 'f1': (0.5922518100396525, 0.0224844164119128)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "model_scores = cross_validate(\n",
    "    classification_pipe,\n",
    "    X_train, \n",
    "    y_train,\n",
    "    cv = cv,\n",
    "    scoring=[\"roc_auc\", \"precision\", \"recall\", \"f1\"],\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "{m: (model_scores[f\"test_{m}\"].mean(), model_scores[f\"test_{m}\"].std()) for m in [\"roc_auc\",\"precision\",\"recall\",\"f1\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58becbd-b3f6-4d13-b26e-f9b79fdb1fb0",
   "metadata": {},
   "source": [
    "## Model Evaluation Summary\n",
    "\n",
    "Cross-validation indicates that the logistic regression pipeline performs\n",
    "consistently across folds (ROC-AUC ≈ 0.89) with high recall for churners.\n",
    "Given the class imbalance, recall is emphasized to reduce missed churn cases,\n",
    "while accepting lower precision. The low variance across folds suggests the\n",
    "model generalizes reliably.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d9fd378-c90d-4a2f-86a5-d835fc6872e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC-AUC: 0.8971343328757202\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.79      0.87      1171\n",
      "           1       0.45      0.86      0.59       237\n",
      "\n",
      "    accuracy                           0.80      1408\n",
      "   macro avg       0.71      0.83      0.73      1408\n",
      "weighted avg       0.88      0.80      0.82      1408\n",
      "\n",
      "[[926 245]\n",
      " [ 33 204]]\n"
     ]
    }
   ],
   "source": [
    "classification_pipe.fit(X_train, y_train)\n",
    "\n",
    "y_prob = classification_pipe.predict_proba(X_test)[:, 1]\n",
    "y_pred = classification_pipe.predict(X_test)\n",
    "\n",
    "print(\"Test ROC-AUC:\", roc_auc_score(y_test, y_prob))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5194fbf4-6c26-4c98-bbe0-ad26d3baae63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold=0.2  Precision=0.299  Recall=0.937  F1=0.453\n",
      "Threshold=0.3  Precision=0.353  Recall=0.920  F1=0.511\n",
      "Threshold=0.4  Precision=0.412  Recall=0.895  F1=0.564\n",
      "Threshold=0.5  Precision=0.454  Recall=0.861  F1=0.595\n",
      "Threshold=0.6  Precision=0.529  Recall=0.797  F1=0.636\n"
     ]
    }
   ],
   "source": [
    "#Evaluate different probability thresholds to understand the precision–recall tradeoff\n",
    "#tradeoff and support business decision making by prioritizing recall to minimize missed churners versus precision to reduce unnecessary outreach)\n",
    "\n",
    "thresholds = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred_t = (y_prob >= t).astype(int)\n",
    "    report = classification_report(y_test, y_pred_t, output_dict=True)\n",
    "    print(\n",
    "        f\"Threshold={t:.1f}  \"\n",
    "        f\"Precision={report['1']['precision']:.3f}  \"\n",
    "        f\"Recall={report['1']['recall']:.3f}  \"\n",
    "        f\"F1={report['1']['f1-score']:.3f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccab08c9-71e3-4bff-9875-dcb65e6fec23",
   "metadata": {},
   "source": [
    "## Threshold Analysis Interpretation\n",
    "\n",
    "Adjusting the classification threshold reveals a clear tradeoff between recall\n",
    "and precision. Lower thresholds prioritize identifying most churners at the cost\n",
    "of increased false positives, while higher thresholds reduce unnecessary outreach\n",
    "but miss more churn cases. A threshold around 0.4–0.5 provides a balanced tradeoff,\n",
    "though the optimal choice depends on business constraints and retention capacity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5209aaf2-047e-469f-bf5a-abf5a7567695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>coefficient</th>\n",
       "      <th>abs_coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>PreferedOrderCat_Others</td>\n",
       "      <td>2.543767</td>\n",
       "      <td>2.543767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tenure</td>\n",
       "      <td>-1.686479</td>\n",
       "      <td>1.686479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>PreferedOrderCat_Laptop &amp; Accessory</td>\n",
       "      <td>-1.677821</td>\n",
       "      <td>1.677821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PreferedOrderCat_Mobile</td>\n",
       "      <td>-1.147181</td>\n",
       "      <td>1.147181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>PreferedOrderCat_Grocery</td>\n",
       "      <td>0.731569</td>\n",
       "      <td>0.731569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Complain</td>\n",
       "      <td>0.716873</td>\n",
       "      <td>0.716873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>PreferedOrderCat_Mobile Phone</td>\n",
       "      <td>-0.703809</td>\n",
       "      <td>0.703809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PreferredPaymentMode_COD</td>\n",
       "      <td>0.668626</td>\n",
       "      <td>0.668626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NumberOfAddress</td>\n",
       "      <td>0.644189</td>\n",
       "      <td>0.644189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PreferredPaymentMode_CC</td>\n",
       "      <td>-0.593912</td>\n",
       "      <td>0.593912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MaritalStatus_Single</td>\n",
       "      <td>0.537813</td>\n",
       "      <td>0.537813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>missingindicator_CouponUsed</td>\n",
       "      <td>-0.477749</td>\n",
       "      <td>0.477749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MaritalStatus_Married</td>\n",
       "      <td>-0.453916</td>\n",
       "      <td>0.453916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OrderCount</td>\n",
       "      <td>0.430532</td>\n",
       "      <td>0.430532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>missingindicator_OrderAmountHikeFromlastYear</td>\n",
       "      <td>-0.420763</td>\n",
       "      <td>0.420763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         feature  coefficient  abs_coefficient\n",
       "37                       PreferedOrderCat_Others     2.543767         2.543767\n",
       "0                                         Tenure    -1.686479         1.686479\n",
       "34           PreferedOrderCat_Laptop & Accessory    -1.677821         1.677821\n",
       "35                       PreferedOrderCat_Mobile    -1.147181         1.147181\n",
       "33                      PreferedOrderCat_Grocery     0.731569         0.731569\n",
       "7                                       Complain     0.716873         0.716873\n",
       "36                 PreferedOrderCat_Mobile Phone    -0.703809         0.703809\n",
       "24                      PreferredPaymentMode_COD     0.668626         0.668626\n",
       "6                                NumberOfAddress     0.644189         0.644189\n",
       "23                       PreferredPaymentMode_CC    -0.593912         0.593912\n",
       "40                          MaritalStatus_Single     0.537813         0.537813\n",
       "19                   missingindicator_CouponUsed    -0.477749         0.477749\n",
       "39                         MaritalStatus_Married    -0.453916         0.453916\n",
       "9                                     OrderCount     0.430532         0.430532\n",
       "15  missingindicator_OrderAmountHikeFromlastYear    -0.420763         0.420763"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now lets look at feature importance by extracting preprocessing/modeling steps from the pipeline\n",
    "log_reg = classification_pipe.named_steps[\"model\"]\n",
    "\n",
    "preprocessor = classification_pipe.named_steps[\"preprocess\"]\n",
    "\n",
    "num_features = preprocessor.named_transformers_[\"num\"] \\\n",
    "    .named_steps[\"imputer\"] \\\n",
    "    .get_feature_names_out(other_numeric_cols)\n",
    "\n",
    "coupon_features = preprocessor.named_transformers_[\"coupon\"] \\\n",
    "    .named_steps[\"imputer\"] \\\n",
    "    .get_feature_names_out(coupon_col)\n",
    "\n",
    "cat_features = preprocessor.named_transformers_[\"cat\"] \\\n",
    "    .named_steps[\"onehot\"] \\\n",
    "    .get_feature_names_out(cols_category)\n",
    "\n",
    "#Combine all feature names\n",
    "feature_names = np.concatenate([\n",
    "    num_features,\n",
    "    coupon_features,\n",
    "    cat_features\n",
    "])\n",
    "\n",
    "#Create coefficient DataFrame\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"coefficient\": log_reg.coef_.ravel()\n",
    "})\n",
    "\n",
    "coef_df[\"abs_coefficient\"] = coef_df[\"coefficient\"].abs()\n",
    "\n",
    "coef_df.sort_values(\"abs_coefficient\", ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57fd585-8058-4a57-909a-e83f94b30711",
   "metadata": {},
   "source": [
    "## Model Interpretation Summary\n",
    "\n",
    "Logistic regression coefficients indicate that tenure and product category\n",
    "preferences are the strongest churn drivers. Longer-tenured customers and those\n",
    "purchasing in core product categories exhibit lower churn risk, while customers\n",
    "with complaints, less stable category behavior, and COD payment preferences are\n",
    "more likely to churn. These associations closely align with patterns observed\n",
    "during EDA, reinforcing the importance of customer longevity, service experience,\n",
    "and purchasing behavior in churn risk.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fc07b1-eb19-49dc-b7ea-5acc80b6ddd2",
   "metadata": {},
   "source": [
    "## Gradient Boosted Tree Model\n",
    "\n",
    "A gradient boosted tree model is trained to capture non-linear relationships\n",
    "and feature interactions that logistic regression may miss by iterratively training on residual error of previous weak learners. Performance will be\n",
    "compared against the baseline model to assess whether additional complexity\n",
    "provides meaningful gains.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00f6bc13-1816-422c-ac05-3c7613322c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc_auc': (0.9382949514870595, 0.011707998241371885),\n",
       " 'precision': (0.8342138918129042, 0.03272835462225324),\n",
       " 'recall': (0.6174332709543977, 0.01826000168339295),\n",
       " 'f1': (0.7092496755686907, 0.017306669540064837)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#use \"full transformer\" from earlier\n",
    "gb_pipe = Pipeline(steps=[\n",
    "    (\"preprocess\", full_transformer),\n",
    "    (\"model\", GradientBoostingClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=3,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "#Use same cv steps as before to estimate how model will preform on unseen data\n",
    "gb_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "gb_scores = cross_validate(\n",
    "    gb_pipe,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=gb_cv,\n",
    "    scoring=[\"roc_auc\", \"precision\", \"recall\", \"f1\"],\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "#See mean/std of metrics \n",
    "{m: (gb_scores[f\"test_{m}\"].mean(), gb_scores[f\"test_{m}\"].std())\n",
    " for m in [\"roc_auc\", \"precision\", \"recall\", \"f1\"]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86164a6b-e22f-44ea-b5d8-8e55160ccd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB Test ROC-AUC: 0.9425425273937311\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      1171\n",
      "           1       0.82      0.63      0.71       237\n",
      "\n",
      "    accuracy                           0.91      1408\n",
      "   macro avg       0.87      0.80      0.83      1408\n",
      "weighted avg       0.91      0.91      0.91      1408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#lets fit and evaluate on test set\n",
    "gb_pipe.fit(X_train, y_train)\n",
    "\n",
    "y_prob_gb = gb_pipe.predict_proba(X_test)[:, 1]\n",
    "y_pred_gb = gb_pipe.predict(X_test)\n",
    "\n",
    "print(\"GB Test ROC-AUC:\", roc_auc_score(y_test, y_prob_gb))\n",
    "print(classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f483efb-05c5-45b0-ada6-61e5428cc254",
   "metadata": {},
   "source": [
    "## Gradient Boost Observations:\n",
    "This model outpreformed the basline logistic regression model in terms of F1, precision, and ROC AUC, but scored lower in terms of recall. This means this model failed to identify as many churners as the baseline model, but was more selective when identifying a customer as a churner. I am interested in how changing the threshold for preicted churners could increase recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "601d6b60-9585-4084-95b2-46d0461ab156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold=0.2 | Precision=0.630 | Recall=0.878 | F1=0.734\n",
      "Threshold=0.3 | Precision=0.714 | Recall=0.831 | F1=0.768\n",
      "Threshold=0.4 | Precision=0.772 | Recall=0.730 | F1=0.751\n",
      "Threshold=0.5 | Precision=0.819 | Recall=0.629 | F1=0.711\n"
     ]
    }
   ],
   "source": [
    "# Threshold analysis for Gradient Boosted Tree (same method as basline)\n",
    "thresholds = [0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred_t = (y_prob_gb >= t).astype(int)\n",
    "    report = classification_report(y_test, y_pred_t, output_dict=True)\n",
    "    print(\n",
    "        f\"Threshold={t:.1f} | \"\n",
    "        f\"Precision={report['1']['precision']:.3f} | \"\n",
    "        f\"Recall={report['1']['recall']:.3f} | \"\n",
    "        f\"F1={report['1']['f1-score']:.3f}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb003ab-7f65-4a00-9deb-272c96fc0e2b",
   "metadata": {},
   "source": [
    "## Business Recommendation: Churn Intervention Strategy\n",
    "\n",
    "Based on the model comparison, the gradient boosted tree is the preferred\n",
    "approach for identifying customers at risk of churn. When the probability\n",
    "threshold is lowered (around 0.2–0.3), the model captures a similar share of\n",
    "churners as the baseline logistic regression while flagging far fewer customers\n",
    "who are unlikely to churn.\n",
    "\n",
    "In practice, this allows retention efforts to be more focused and efficient.\n",
    "Customers identified as high risk can be prioritized for targeted outreach,\n",
    "such as personalized incentives, follow-up communication, or service recovery\n",
    "actions. At the same time, reducing false positives helps limit unnecessary\n",
    "outreach and associated operational costs.\n",
    "\n",
    "The probability threshold can be adjusted depending on business needs, such as\n",
    "available retention budget, customer lifetime value, or campaign capacity.\n",
    "Overall, this approach balances the goal of preventing churn with the practical\n",
    "constraints of running scalable retention programs.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
